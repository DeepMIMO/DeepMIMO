{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c338c11-529e-4d6b-bf68-0ab5f0bd4bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Aug 13 17:35:31 2023\n",
    "\n",
    "@author: joao\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d54adf-f302-474f-8d58-ce9a07320a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\" Run Blender \"\n",
    "import subprocess\n",
    "\n",
    "command = [\"/home/joao/blender-3.6.0-linux-x64/blender\",\n",
    "           \"--background\",\n",
    "           \"--python\",\n",
    "           \"/mnt/c/Users/jmora/Documents/GitHub/AutoRayTracing/scene_creation.py\"\n",
    "          ]\n",
    "try:\n",
    "    result = subprocess.run(command, check=True, text=True, capture_output=True)\n",
    "    print(\"Output:\", result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Error:\", e.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65f3f0-55ab-4099-97e6-f043789d4677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "gpu_num = 0 # Use \"\" to use the CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "# Avoid warnings from TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(1) # Set global random seed for reproducibility\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sionna\n",
    "from sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, DirectivePattern\n",
    "from sionna.channel import ApplyTimeChannel, cir_to_ofdm_channel\n",
    "\n",
    "from tqdm import tqdm\n",
    "import mitsuba as mi\n",
    "import drjit as dr\n",
    "import time\n",
    "from scipy.io import loadmat, savemat\n",
    "import pandas as pd\n",
    "\n",
    "with open('scenes_folder.txt', 'r') as fp:\n",
    "    root_folder = fp.read()[:-1] # no newline\n",
    "\n",
    "print(root_folder) ######## SHOULD HAVE WRITTEN THE PATH OBTAINED FROM BLENDER -> WE SHOULD HAVE BLENDER 3.6 INSTALLED IN WSL too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd73b7f-5ba7-4477-a5a7-45a526740dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca5f78f-381b-4ed9-9651-3ffa5fdbb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "class Shape:\n",
    "    \n",
    "    # bbox Mitsuba API: https://mitsuba.readthedocs.io/en/stable/src/api_reference.html#mitsuba.ScalarBoundingBox3f\n",
    "    def __init__(self, shape):\n",
    "        self.id = shape.id()\n",
    "        self.shape = shape\n",
    "        params = mi.traverse(shape)\n",
    "        self.faces = dr.unravel(mi.Point3f, params['faces']).numpy()\n",
    "        self.vertices = dr.unravel(mi.Point3f, params['vertex_positions']).numpy()\n",
    "        self.bbox = shape.bbox()\n",
    "        \n",
    "    def get_vertices(self):\n",
    "        return self.vertices\n",
    "    \n",
    "    def get_faces(self):\n",
    "        return self.faces\n",
    "\n",
    "    def contains(self, pos):\n",
    "        return self.bbox.contains(pos)\n",
    "\n",
    "    def get_size(self):\n",
    "        return self.bbox.extents()\n",
    "\n",
    "    def get_3d_area(self):\n",
    "        return self.bbox.surface_area()\n",
    "\n",
    "    def get_volume(self):\n",
    "        return self.bbox.volume()\n",
    "\n",
    "    def get_bbox_corners(self):\n",
    "        return self.bbox.min, self.bbox.max\n",
    "\n",
    "    def get_height(self):\n",
    "        return self.bbox.max[2] - self.bbox.min[2]\n",
    "        \n",
    "    def get_center(self):\n",
    "        return self.bbox.center\n",
    "\n",
    "    def get_distance(self, target):\n",
    "        return self.bbox.distance(target)\n",
    "\n",
    "    def get_bbox(self):\n",
    "        return self.bbox\n",
    "\n",
    "    def get_bbox_bottom_vertices(self):\n",
    "        return [self.bbox.corner(i) for i in range(4)]\n",
    "    \n",
    "    def get_bbox_top_vertices(self):\n",
    "        return [self.bbox.corner(4+i) for i in range(4)]\n",
    "\n",
    "    def get_bbox_vertices(self):\n",
    "        return [self.bbox.corner(i) for i in range(8)]\n",
    "    \n",
    "\n",
    "# Functions\n",
    "def print_all_shapes_in_scene(scene):\n",
    "    for shape in scene.mi_scene.shapes():\n",
    "        print(shape.id())\n",
    "\n",
    "def get_floor_from_scene(scene):\n",
    "    floor_shape = None\n",
    "    for shape in scene.mi_scene.shapes():\n",
    "        if shape.id() == 'mesh-floor':\n",
    "            floor_shape = shape\n",
    "            break\n",
    "\n",
    "    return shape\n",
    "\n",
    "def get_buildings_from_scene(scene):\n",
    "    buildings = []\n",
    "    for shape in scene.mi_scene.shapes():\n",
    "        if shape.id() != 'mesh-floor':\n",
    "            buildings.append(shape)\n",
    "\n",
    "    return buildings\n",
    "\n",
    "def compute_array_combinations(arrays):\n",
    "    return np.stack(np.meshgrid(*arrays), -1).reshape(-1, len(arrays))\n",
    "\n",
    "def gen_user_grid(box_corners, steps, no_zones=None, box_offsets=None):\n",
    "    \"\"\"\n",
    "    box_corners is = [bbox_min_corner, bbox_max_corner]\n",
    "    steps = [x_step, y_step, z_step]\n",
    "    no_zones = [list of Shapes with a contains() method]\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample the ranges of coordinates\n",
    "    ndim = len(box_corners[0])\n",
    "    dim_ranges = []\n",
    "    for dim in range(ndim):\n",
    "        if steps[dim]:\n",
    "            dim_range = np.arange(box_corners[0][dim], box_corners[1][dim], steps[dim])\n",
    "        else:\n",
    "            dim_range = np.array([box_corners[0][dim]]) # select just the first limit\n",
    "        \n",
    "        dim_ranges.append(dim_range + box_offsets[dim] if box_offsets else 0)\n",
    "    \n",
    "    dims = [len(r) if len(r) else 1 for r in dim_ranges]\n",
    "    print(f'Grid dimensions: {dims}')\n",
    "    \n",
    "    n_total = np.prod(dims)\n",
    "    print(f'Total positions covering the ground plane: {n_total}')\n",
    "    \n",
    "    # Compute combination of sampled ranges\n",
    "    positions = compute_array_combinations(dim_ranges)\n",
    "    \n",
    "    # Determine which positions are inside no_zones\n",
    "    idxs_in_nozone = np.zeros(positions.shape[0], dtype=bool)\n",
    "    for pos_idx in tqdm(range(n_total), desc='Intersecting positions with no-zones (e.g. buildings)'):\n",
    "        for no_zone in no_zones:\n",
    "            if no_zone.contains(positions[pos_idx]):\n",
    "                idxs_in_nozone[pos_idx] = True\n",
    "                break\n",
    "    \n",
    "    # Include only the positions that are outside no zones\n",
    "    idxs_to_include = np.invert(idxs_in_nozone)\n",
    "    \n",
    "    n_total_after_filtering = sum(idxs_to_include)\n",
    "    print(f'Total positions outside of buildings: {n_total_after_filtering}')\n",
    "    \n",
    "    return positions[idxs_to_include]\n",
    "\n",
    "def is_notebook() -> bool:\n",
    "    is_notebook = False\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        module = get_ipython().__class__.__module__\n",
    "    except NameError:\n",
    "        return False # Probably standard Python interpreter\n",
    "        \n",
    "    if shell == 'ZMQInteractiveShell':\n",
    "        is_notebook = True   # Jupyter notebook or qtconsole\n",
    "    elif module == 'google.colab._shell':\n",
    "        is_notebook = True   # Colab notebook\n",
    "    elif shell == 'TerminalInteractiveShell':\n",
    "        is_notebook = False  # Terminal running IPython\n",
    "    else:\n",
    "        is_notebook = False  # Other type (?)\n",
    "\n",
    "    return is_notebook\n",
    "\n",
    "def create_base_scene(scene_path, center_frequency):\n",
    "    scene = load_scene(scene_path)\n",
    "    scene.frequency = center_frequency\n",
    "    scene.tx_array = PlanarArray(num_rows=1,\n",
    "                                 num_cols=1,\n",
    "                                 vertical_spacing=0.5,\n",
    "                                 horizontal_spacing=0.5,\n",
    "                                 pattern=\"iso\",\n",
    "                                 polarization=\"V\")\n",
    "    \n",
    "    scene.rx_array = scene.tx_array\n",
    "    scene.synthetic_array = True\n",
    "    \n",
    "    return scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857b7fd-a0fb-4702-946b-dd24bd3c12a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read parameters from CSV\n",
    "df = pd.read_csv('params.csv')\n",
    "\n",
    "# Compute simulations for each row\n",
    "n_rows = df.index.stop\n",
    "\n",
    "for row_idx in range(n_rows):\n",
    "    carrier_freq = df['freq (ghz)'][row_idx] * 1e9\n",
    "    n_reflections = df['n_reflections'][row_idx]\n",
    "    \n",
    "    if not np.isnan(df['bs_lat'][row_idx]):\n",
    "        tx_pos = [df['bs_lat'][row_idx], df['bs_lon'][row_idx], df['bs_alt'][row_idx]]\n",
    "    else:\n",
    "        tx_pos = None # placed automatically on building closest to the center\n",
    "        \n",
    "    scattering = bool(df['scattering'][row_idx])\n",
    "    diffraction = bool(df['diffraction'][row_idx])\n",
    "    \n",
    "    x_step = df['x_step'][row_idx]\n",
    "    y_step = df['y_step'][row_idx]\n",
    "    z_step = df['z_step'][row_idx]\n",
    "\n",
    "    print(f'Running RT simulation for row {row_idx+1} (starts at 1):\\n'\n",
    "          f'n_reflections = {n_reflections}\\n'\n",
    "          f'tx_pos = {tx_pos}\\n'\n",
    "          f'scattering = {scattering}\\n'\n",
    "          f'diffraction = {diffraction}\\n'\n",
    "          f'[x_step, y_step, z_step] = [{x_step}, {y_step}, {z_step}]\\n')\n",
    "\n",
    "    # 0- Create/Fetch scene and get buldings in the scene\n",
    "    #scene_name = sionna.rt.scene.simple_street_canyon\n",
    "    scene_folder = root_folder + f'scen_{row_idx}/'\n",
    "    scene_name = scene_folder + 'scene.xml'\n",
    "    scene = create_base_scene(scene_name, center_frequency=carrier_freq)\n",
    "    buildings = [Shape(building) for building in get_buildings_from_scene(scene)][:-1] \n",
    "    # (unkown last building in bottom left corner...)\n",
    "\n",
    "    # 1- Compute TX position\n",
    "    print('Computing BS position')\n",
    "    \n",
    "    # 1.1- Find the building closest to the center of the scene ([0,0,0])\n",
    "    distances = [building.get_distance([0,0,0]) for building in buildings]\n",
    "    heights = [building.get_height() for building in buildings]\n",
    "    building_score = [heights[b]**2/distances[b] for b in range(len(buildings))]\n",
    "    best_building_idx = np.argmax(building_score)\n",
    "    closest_building = buildings[best_building_idx]\n",
    "\n",
    "    # 1.2- Find closest vertice to the origin (at height)\n",
    "    best_building_vertices = closest_building.get_vertices()\n",
    "    # use a high point at the origin to force the selection of a roof vertice\n",
    "    vertice_distances = [np.linalg.norm(vert - [0,0,1e5]) for vert in best_building_vertices]\n",
    "    closest_vertice_idx = np.argmin(vertice_distances)\n",
    "    closest_vertice = best_building_vertices[closest_vertice_idx]\n",
    "    \n",
    "    # 1.3- Put transmitter 2 metters above that vertice\n",
    "    tx_pos = closest_vertice + [0,0,2] if not tx_pos else tx_pos\n",
    "\n",
    "    # 1.4- Add transmitter to the scene\n",
    "    scene.add(Transmitter(name=\"tx\",\n",
    "                          position=tx_pos,\n",
    "                          orientation=[0,0,0]))\n",
    "\n",
    "    # 2- Compute RXs positions\n",
    "    print('Computing UEs positions')\n",
    "    \n",
    "    # 2.1- Get limits of the floor\n",
    "    floor_shape = Shape(get_floor_from_scene(scene))\n",
    "    min_corner, max_corner = floor_shape.get_bbox_corners()\n",
    "    c = 1.2 # constant of floor overscaling to account for edge effects\n",
    "\n",
    "    # 2.2- Distribute users uniformely 1.5m above the floor\n",
    "    rxs = gen_user_grid(box_corners=[min_corner/c, max_corner/c],\n",
    "                        steps=[x_step,y_step,z_step],\n",
    "                        no_zones=buildings,\n",
    "                        box_offsets=[0,0,1.5])\n",
    "\n",
    "    # 2.3- Add (ONLY SOME OF THE) receivers to the scene\n",
    "    n_rx = len(rxs)\n",
    "    n_rx_in_scene = 20 if not scattering else 1\n",
    "    print(f'Adding users to the scene ({n_rx_in_scene} at a time)')\n",
    "    for rx_idx in range(n_rx_in_scene):\n",
    "        scene.add(Receiver(name=f\"rx_{rx_idx}\",\n",
    "                           position=rxs[rx_idx],\n",
    "                           orientation=[0,0,0]))\n",
    "\n",
    "    # 3- Compute paths\n",
    "    # 3.1- Enable scattering in the radio materials\n",
    "    if scattering:\n",
    "        for rm in scene.radio_materials.values():\n",
    "            rm.scattering_coefficient = 1/np.sqrt(3) # [0,1]\n",
    "            rm.scattering_pattern = DirectivePattern(alpha_r=10)\n",
    "            \n",
    "\n",
    "    # 3.2- Compute the paths for each set of receiver positions\n",
    "    path_list = []\n",
    "    n_rx_remaining = n_rx\n",
    "    for x in tqdm(range(int(n_rx / n_rx_in_scene)+1), desc='Path computation'):\n",
    "        if n_rx_remaining > 0:\n",
    "            n_rx_remaining -= n_rx_in_scene\n",
    "        else:\n",
    "            break\n",
    "        if x != 0:\n",
    "            # modify current RXs in scene\n",
    "            for rx_idx in range(n_rx_in_scene):\n",
    "                if rx_idx + n_rx_in_scene*x < n_rx:\n",
    "                    scene.receivers[f'rx_{rx_idx}'].position = rxs[rx_idx + n_rx_in_scene*x]\n",
    "                else:\n",
    "                    # remove the last receivers in the scene\n",
    "                    scene.remove(f'rx_{rx_idx}')\n",
    "            \n",
    "        paths = scene.compute_paths(max_depth=n_reflections,\n",
    "                                    num_samples=1e6,\n",
    "                                    scattering=scattering,\n",
    "                                    diffraction=diffraction)\n",
    "        path_list.append(paths)\n",
    "    \n",
    "    # 4- Save paths\n",
    "    print('Building path matrices')\n",
    "    n_rx = len(rxs)\n",
    "    path_matrices = []\n",
    "    empty_paths_warning = False\n",
    "    for idx, paths in enumerate(path_list):\n",
    "        if False:\n",
    "            print(f'paths idx = {idx}')\n",
    "            # [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths, num_time_steps]\n",
    "            print(f'a = {paths.a.shape}')\n",
    "            # print(f'tau = {paths.tau.shape}')         # [batch_size, num_rx, num_tx, max_num_paths]\n",
    "            # print(f'phi_r = {paths.phi_r.shape}')     # [batch_size, num_rx, num_tx, max_num_paths],\n",
    "            # print(f'phi_t = {paths.phi_t.shape}')     # [batch_size, num_rx, num_tx, max_num_paths],\n",
    "            # print(f'theta_r = {paths.theta_r.shape}') # [batch_size, num_rx, num_tx, max_num_paths],\n",
    "            # print(f'theta_t = {paths.theta_t.shape}') # [batch_size, num_rx, num_tx, max_num_paths],\n",
    "            # print(f'type = {paths.types.shape}')      # [batch_size, max_num_paths]\n",
    "        \n",
    "        phase = np.angle(paths.a.numpy(), deg=True)\n",
    "        ToA   = paths.tau.numpy()\n",
    "        power = 20 * np.log10(np.absolute(paths.a.numpy()))\n",
    "        DoA_phi   = paths.phi_r.numpy()   * 180 / np.pi\n",
    "        DoA_theta = paths.theta_r.numpy() * 180 / np.pi\n",
    "        DoD_phi   = paths.phi_t.numpy()   * 180 / np.pi\n",
    "        DoD_theta = paths.theta_t.numpy() * 180 / np.pi\n",
    "    \n",
    "        # Generate 8 by X matrices, X = number of paths\n",
    "        for i in range(paths.a.shape[1]):\n",
    "            # determine which paths exist (non-existing paths have negative delays)\n",
    "            non_zero_paths = np.where(paths.tau.numpy()[0,i,0,:] > 0)[0]\n",
    "\n",
    "            if np.size(non_zero_paths) == 0:\n",
    "                if not empty_paths_warning:\n",
    "                    print('Warning: Some paths are empty. Number of reflections may not be enough')\n",
    "                    empty_paths_warning = True\n",
    "                path_matrix = np.zeros((8, len(non_zero_paths)))\n",
    "                path_matrix[1,:] = -1 # negative delays!\n",
    "            else:\n",
    "                path_matrix = np.zeros((8, len(non_zero_paths)))\n",
    "    \n",
    "                # determine which paths are  LoS\n",
    "                los = np.zeros_like(non_zero_paths)\n",
    "                los[0] = 1 if (0 in non_zero_paths and paths.types.numpy()[0,0] == 0) else 0\n",
    "                \n",
    "                path_matrix = np.vstack((\n",
    "                    phase[0, i, 0, 0, 0, non_zero_paths, 0],\n",
    "                    ToA[0, i, 0, non_zero_paths],\n",
    "                    power[0, i, 0, 0, 0, non_zero_paths, 0],\n",
    "                    DoA_phi[0, i, 0, non_zero_paths],\n",
    "                    DoA_theta[0, i, 0, non_zero_paths],\n",
    "                    DoD_phi[0, i, 0, non_zero_paths],\n",
    "                    DoD_theta[0, i, 0, non_zero_paths],\n",
    "                    los))\n",
    "                \n",
    "                # sort paths based on received power\n",
    "                path_matrix = path_matrix[:, np.flip(path_matrix[2,:].argsort())] \n",
    "                \n",
    "            path_matrices.append(path_matrix)\n",
    "        \n",
    "    # 5- Save data for DeepMIMO \n",
    "    # 5.1- Create BS file\n",
    "    dict_bs = {\n",
    "        'channels': [{'p': []}],\n",
    "        'rx_locs': [tx_pos[0], tx_pos[1], tx_pos[2], 0, 0],\n",
    "    }\n",
    "    # 5.2- Create users file\n",
    "    rx_locs = np.zeros((n_rx, 5))\n",
    "    rx_locs[:, :3] = rxs\n",
    "    ues_channels = [{'p': path_matrices[i]} for i in range(n_rx)]\n",
    "    dict_ues = {\n",
    "        'channels': ues_channels,\n",
    "        'rx_locs': rx_locs,\n",
    "    }\n",
    "\n",
    "    # CHECK why the -INF and why the (8,0) matrices!!!!!\n",
    "                \n",
    "    # 5.3- Create parameters file\n",
    "    params_file = {\n",
    "        'carrier_freq': carrier_freq,\n",
    "        'doppler_available': 0,\n",
    "        'dual_polar_available': 0,\n",
    "        'num_BS': 1,\n",
    "        'transmit_power': 0.0,\n",
    "        'user_grids': [1.0, 1.0, n_rx],\n",
    "        'version': 2,\n",
    "    }\n",
    "    \n",
    "    # 5.4- Save data\n",
    "    mat_folder = scene_folder + 'DeepMIMO_folder/'\n",
    "    os.makedirs(mat_folder, exist_ok=True)\n",
    "    savemat(mat_folder +  'BS1_BS.mat', dict_bs)\n",
    "    savemat(mat_folder + f'BS1_UE_0-{n_rx}.mat', dict_ues)\n",
    "    savemat(mat_folder + f'params.mat', params_file)\n",
    "\n",
    "    # NOTE: warning is normal\n",
    "    # RuntimeWarning: divide by zero encountered in log10power = 20 * np.log10(np.absolute(paths.a.numpy()))\n",
    "    # This happens because some positions don't have any paths to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebe078-aa68-4bc8-a45f-30fa438d162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "a = 'C:/Users/jmora/Documents/GitHub/AutoRayTracing/all_runs/run_02-02-2025_14H20M53S/scen_0/scene.xml'\n",
    "b = r'C:\\Users\\jmora\\Documents\\GitHub\\AutoRayTracing\\all_runs\\run_02-02-2025_14H20M53S\\scen_0\\scene.xml'\n",
    "os.path.exists(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9aaa852-40af-41f4-9753-89e224caf25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1346de-2eeb-4de6-8c0d-6c8bee2229cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_test = loadmat(mat_folder + f'BS1_UE0-{n_rx}.mat')\n",
    "\n",
    "# Check for -inf powers\n",
    "n_users = len(m_test['channels'][0])\n",
    "count_infs = 0\n",
    "for i in range(n_users):\n",
    "    count_infs = np.sum(len(np.where(np.isinf(m_test['channels'][0][i][0][0][0]))[0]))\n",
    "    \n",
    "print(f'count_infs = {count_infs}')\n",
    "\n",
    "# Check for empty matrices (users with no paths)\n",
    "emtpy_matrices = 0\n",
    "for i in range(n_users):\n",
    "    if m_test['channels'][0][i][0][0][0].shape[1] == 0:\n",
    "        emtpy_matrices += 1\n",
    "print(f'empty_matrices = {emtpy_matrices}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
